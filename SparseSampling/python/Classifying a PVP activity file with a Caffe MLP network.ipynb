{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sparse\n",
    "import lmdb\n",
    "\n",
    "# Add paths\n",
    "sys.path.insert(0, os.path.abspath('../../../python/')) # PetaVision\n",
    "sys.path.insert(0, os.path.abspath(os.environ['HOME']+'/Work/Libraries/caffe/python/')) # Caffe\n",
    "\n",
    "# Import aux libraries\n",
    "from pvtools import *\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set up path to pvp file\n",
    "pvp_file_path = os.environ['HOME']+'/Work/LANL/Data/S1_400.pvp'\n",
    "image_list_path = os.environ['HOME']+'/Work/LANL/Data/mixed_cifar.txt'\n",
    "lmdb_file_name = 'pvCifar_train_lmdb'\n",
    "proto_file_name = 'mlp.prototxt'\n",
    "solver_file_name = 'solver.prototxt'\n",
    "\n",
    "#MLP params\n",
    "batch_size = 64       #Batch size for training with SGD\n",
    "num_ip1_params = 500  #Number of free parameters in ip1\n",
    "ip1_lrm_weights = 1   #Learning rate multiplier for ip1 weights\n",
    "ip1_lrm_bias = 2      #Learning rate multiplyer for ip1 bias\n",
    "ip2_lrm_weights = 1   #Learning rate multiplier for ip2 weights\n",
    "ip2_lrm_bias = 2      #Learning rate multiplier for ip2 bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pvObj2DenseMat(pvObj):\n",
    "    numIm = len(pvObj)\n",
    "    numF = pvObj.header['nf']\n",
    "    numY = pvObj.header['ny']\n",
    "    numX = pvObj.header['nx']\n",
    "    dense_shape = numF * numY * numX\n",
    "    out_mat = np.zeros((numIm, numF, numY, numX))\n",
    "    for frame_idx in range(numIm):\n",
    "        frame_indices = np.array(pvObj[frame_idx].values)[:,0].astype(np.int32)\n",
    "        frame_data = np.array(pvObj[frame_idx].values)[:,1].astype(np.float32)\n",
    "        numActive = len(frame_indices)\n",
    "        ij_mat = (np.zeros(numActive), frame_indices)\n",
    "        out_vec = np.array(sparse.coo_matrix((frame_data, ij_mat), shape=(1, dense_shape)).todense())\n",
    "        out_mat[frame_idx,:,:,:] = out_vec.reshape((numF, numY, numX))\n",
    "    return out_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cifarList2Vec(file_loc,label_pos):\n",
    "    label_list = []\n",
    "    with open(file_loc, 'r') as f:\n",
    "        for line in f:\n",
    "            line_arry = line.split('/')\n",
    "            label_list.append(line_arry[label_pos])\n",
    "    return np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pvData = readpvpfile(pvp_file_path) # This takes some time...\n",
    "pvActivities = pvObj2DenseMat(pvData)\n",
    "labels = cifarList2Vec(image_list_path, 6).astype(np.int64)\n",
    "assert labels.shape[0] == pvActivities.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Database size set to be 10x bigger than needed\n",
    "# as suggested in http://deepdish.io/2015/04/28/creating-lmdb-in-python/\n",
    "map_size = pvActivities.nbytes * 10\n",
    "\n",
    "env = lmdb.open(lmdb_file_name, map_size=map_size)\n",
    "with env.begin(write=True) as txn:   # txn is a Transaction object\n",
    "    for i in range(len(pvData)):\n",
    "        datum = caffe.proto.caffe_pb2.Datum()\n",
    "        datum.channels = pvActivities.shape[1]\n",
    "        datum.height = pvActivities.shape[2]\n",
    "        datum.width = pvActivities.shape[3]\n",
    "        datum.data = pvActivities[i].tobytes()\n",
    "        datum.label = int(labels[i])\n",
    "        str_id = '{:08}'.format(i)\n",
    "        txn.put(str_id.encode('ascii'), datum.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from caffe import layers as L, params as P, to_proto\n",
    "\n",
    "netSpec = caffe.NetSpec()\n",
    "netSpec.data, netSpec.label = L.Data(batch_size=batch_size, backend=P.Data.LMDB, source=lmdb_file_name, \\\n",
    "        transform_param=dict(scale=1./255), phase=0, ntop=2)\n",
    "\n",
    "\n",
    "netSpec.ip1 = L.InnerProduct(netSpec.data, num_output=num_ip1_params, \\\n",
    "        weight_filler={'type': 'xavier'}, \\\n",
    "        bias_filler={'type': 'constant', 'value': 0})\n",
    "netSpec.ip1.fn.params['param'] = [{'lr_mult': ip1_lrm_weights, 'decay_mult': 1}, \\\n",
    "                                  {'lr_mult': ip1_lrm_bias, 'decay_mult': 1}]\n",
    "\n",
    "netSpec.relu1 = L.ReLU(netSpec.ip1, in_place=True)\n",
    "\n",
    "netSpec.ip2 = L.InnerProduct(netSpec.data, num_output=10, \\\n",
    "        weight_filler={'type': 'xavier'}, \\\n",
    "        bias_filler={'type': 'constant', 'value': 0})\n",
    "netSpec.ip2.fn.params['param'] = [{'lr_mult': ip2_lrm_weights, 'decay_mult': 1}, \\\n",
    "                                  {'lr_mult': ip2_lrm_bias, 'decay_mult': 1}]\n",
    "\n",
    "#netSpec.accuracy = L.Accuracy(netSPec.ip2, netSpec.label, include={phase: 'TEST'})\n",
    "\n",
    "netSpec.loss = L.SoftmaxWithLoss(netSpec.ip2, netSpec.label)\n",
    "\n",
    "open(proto_file_name,\"w\").write(str(netSpec.to_proto()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('checkpoints'):\n",
    "    os.makedirs('checkpoints')\n",
    "\n",
    "solver = caffe.SGDSolver(solver_file_name)\n",
    "net = solver.net\n",
    "solver.solve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
