\RequirePackage{fix-cm}

%\documentclass{svjour3}                     % onecolumn (standard format)
%\documentclass[smallcondensed]{svjour3}     % onecolumn (ditto)
\documentclass[smallextended]{svjour3}       % onecolumn (second format)
%\documentclass[twocolumn]{svjour3}          % twocolumn

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{tabto}
%\usepackage{latexsym}
%\usepackage{mathptmx}      % use Times fonts if available on your TeX system

\smartqed  % flush right qed marks, e.g. at end of proof

% Math definitions
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\newcommand{\tightoverset}[2]{\mathop{#2}\limits^{\vbox to -.6ex{\kern-0.75ex\hbox{$#1$}\vss}}}
%\newcommand{\tab}[1]{%
%    \settowidth{\tabcont}{#1}
%    {\makebox[0.15\linewidth][l]{#1}\ignorespaces}
%}%

% Insert the name of "your journal" with
\journalname{Neuro-Inspired Computational Elements Workshop}

\begin{document}

\title{Sampling $l_0$ Sparse Codes Leades to Improved Classification Performance
%\thanks{Grants or other notes
%about the article that should go on the front page should be
%placed here. General acknowledgments should be placed at the end of the article.}
}

%\subtitle{}

%\titlerunning{Short form of title}        % if too long for running head

\author{William B. Shainin \and
        Dylan M. Paiton \and
        Garrett T. Kenyon \and
        Bruno Olshausen}


\authorrunning{WB Shainin et al.}% if too long for running head


\institute{WB Shainin\at
              The New Mexico Consortium\\
              Los Alamos, New Mexico\\
              \email{wshainin@gmail.com}           %  \\
}

\date{}

\maketitle

\begin{abstract}
Weights learned from natural scenes via the $l_{0}$ sparse coding energy function have been shown to match well to classical and non-classical biological receptive field properties of pyramidal cells in primary visual cortex. However, the $l_{0}$ energy function is non-convex and thus without a known global minima. Therefore, a network that minimizes an $l_{0}$ cost function could fall into any number of minima that lie along a manifold representing the space of possible representations of the input data. It is not clear how the amount of information differs between these minima, or how the energy level varies between minima. We propose the hypothesis that these local minima have varying support for whole-scene object classification. We test the hypothesis by stochastically sampling multiple fixed points of the Hopfield-like LCA sparse solver network for a basis set learned with an $l_{0}$ sparse coding energy function. We show that sampling multiple local minima in the energy landscape enables improved classification performance.
\end{abstract}

%\begin{acknowledgements}
%
%\end{acknowledgements}

% BibTeX users please use one of
%\bibliographystyle{spbasic}   % basic style, author-year citations
%\bibliographystyle{spmpsci}    % mathematics and physical sciences
%\bibliographystyle{spphys}    % APS-like style for physics
%\bibliography{bib} % name your BibTeX data base

\end{document}

